{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import yaml\n",
    "\n",
    "import basedosdados as bd\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- identificar dataset e table ID\n",
    "- sync_bucket -> public_bucket= basedosdados-dev to basedosdados\n",
    "- tablecreate(), table.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/AEB0CCA7B0CC777D/Jlab/gabinete_sv/bd+/mais_projects/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basedosdados import Storage\n",
    "def sync_bucket(\n",
    "    source_bucket_name,\n",
    "    dataset_id,\n",
    "    table_id,\n",
    "    destination_bucket_name,\n",
    "    backup_bucket_name,\n",
    "    mode=\"staging\",\n",
    "):\n",
    "    \"\"\"Copies proprosed data between storage buckets.\n",
    "    Creates a backup of old data, then delete it and copies new data into the destination bucket.\n",
    "\n",
    "    Args:\n",
    "        source_bucket_name (str):\n",
    "            The bucket name from which to copy data.\n",
    "        dataset_id (str):\n",
    "            Dataset id available in basedosdados. It should always come with table_id.\n",
    "        table_id (str):\n",
    "            Table id available in basedosdados.dataset_id.\n",
    "            It should always come with dataset_id.\n",
    "        destination_bucket_name (str):\n",
    "            The bucket name which data will be copied to.\n",
    "            If None, defaults to the bucket initialized when instantianting Storage object\n",
    "            (check it with the Storage.bucket proprerty)\n",
    "        backup_bucket_name (str):\n",
    "            The bucket name for where backup data will be stored.\n",
    "        mode (str): Optional.\n",
    "         Folder of which dataset to update.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:\n",
    "            If there are no files corresponding to the given dataset_id and table_id on the source bucket\n",
    "    \"\"\"\n",
    "\n",
    "    ref = Storage(dataset_id=dataset_id, table_id=table_id)\n",
    "\n",
    "    prefix = f\"{mode}/{dataset_id}/{table_id}/\"\n",
    "\n",
    "    source_ref = (\n",
    "        ref.client[\"storage_staging\"]\n",
    "        .bucket(source_bucket_name)\n",
    "        .list_blobs(prefix=prefix)\n",
    "    )\n",
    "\n",
    "    destination_ref = ref.bucket.list_blobs(prefix=prefix)\n",
    "\n",
    "    if len(list(source_ref)) == 0:\n",
    "\n",
    "        raise ValueError(\"No objects found on the source bucket\")\n",
    "\n",
    "    else:\n",
    "        # MAKE A BACKUP OF OLD DATA\n",
    "        if len(list(destination_ref)):\n",
    "            ref.copy_table(\n",
    "                source_bucket_name=destination_bucket_name,\n",
    "                destination_bucket_name=backup_bucket_name,\n",
    "            )\n",
    "\n",
    "            # DELETE OLD DATA FROM PROD\n",
    "            ref.delete_table(not_found_ok=True)\n",
    "\n",
    "        # COPIES DATA TO DESTINATION\n",
    "        ref.copy_table(source_bucket_name=source_bucket_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from basedosdados.base import Base\n",
    "import basedosdados as bd\n",
    "\n",
    "def load_configs(dataset_id, table_id):\n",
    "    configs_path = Base()._load_config()\n",
    "    metadata_path = configs_path[\"metadata_path\"]\n",
    "    table_path = f\"{metadata_path}/{dataset_id}/{table_id}\"\n",
    "    \n",
    "    return yaml.load(\n",
    "        open(f\"{table_path}/table_config.yaml\", \"r\"), Loader=yaml.FullLoader\n",
    "    ), configs_path\n",
    "\n",
    "\n",
    "def replace_project_id(configs_path):\n",
    "    \n",
    "    bq_prod_id = configs_path['gcloud-projects']['prod']['name']\n",
    "    bq_staging_id = configs_path['gcloud-projects']['staging']['name']\n",
    "    \n",
    "    sql_file = Path(table_path  + '/publish.sql').open('r').readlines()\n",
    "\n",
    "    sql_lines = [line for line in sql_file if f'.{table_id}' in line]\n",
    "\n",
    "    prod_id    = sql_lines[0].split('VIEW ')[1].split('.')[0]\n",
    "    staging_id = sql_lines[1].split('from ')[1].split('.')[0]\n",
    "\n",
    "    sql_final = [line.replace(f'VIEW {prod_id}',f'VIEW {bq_prod_id}') for line in sql_file]\n",
    "    sql_final = [line.replace(f'from {staging_id}',f'from {bq_staging_id}') for line in sql_final]\n",
    "    \n",
    "    \n",
    "    Path(table_path  + '/publish.sql').open('w').write(''.join(sql_final))\n",
    "    \n",
    "\n",
    "def is_partitioned(table_config):\n",
    "    return table_config[\"partitions\"] is not None\n",
    "\n",
    "\n",
    "def push_table_to_bq(dataset_id,\n",
    "                     table_id,\n",
    "                     source_bucket_name='basedosdados',\n",
    "                     destination_bucket_name='basedosdados-sv',\n",
    "                     backup_bucket_name='basedosdados-sv-bkp'\n",
    "                    ):\n",
    "    \n",
    "    sync_bucket(source_bucket_name,\n",
    "            dataset_id,\n",
    "            table_id,\n",
    "            destination_bucket_name,\n",
    "            backup_bucket_name\n",
    "        )\n",
    "    \n",
    "    table_config, configs_path = load_configs(dataset_id, table_id)\n",
    "    replace_project_id(configs_path)\n",
    "    \n",
    "    tb = bd.Table(table_id, dataset_id)\n",
    "    tb.create('',\n",
    "          if_table_exists=\"replace\",\n",
    "          if_storage_data_exists=\"pass\",\n",
    "          if_table_config_exists=\"pass\",\n",
    "          partitioned=is_partitioned(table_config))\n",
    "    \n",
    "    tb.publish(if_exists=\"replace\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staging/a_proposal_test/proposal_test_table/test_data.csv copied sucessfully to basedosdados-sv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gabinete-sv gabinete-sv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "push_table_to_bq(dataset_id='a_proposal_test', table_id='proposal_test_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = bd.Table('proposal_test_table','a_proposal_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.delete('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staging/a_proposal_test/proposal_test_table/test_data.csv deleted sucessfully!\n"
     ]
    }
   ],
   "source": [
    "bd.Storage('a_proposal_test','proposal_test_table').delete_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
